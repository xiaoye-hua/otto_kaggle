{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005198,
     "end_time": "2022-11-10T16:03:20.966987",
     "exception": false,
     "start_time": "2022-11-10T16:03:20.961789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Candidate ReRank Model using Handcrafted Rules\n",
    "In this notebook, we present a \"candidate rerank\" model using handcrafted rules. We can improve this model by engineering features, merging them unto items and users, and training a reranker model (such as XGB) to choose our final 20. Furthermore to tune and improve this notebook, we should build a local CV scheme to experiment new logic and/or models.\n",
    "\n",
    "UPDATE: I published a notebook to compute validation score [here][10] using Radek's scheme described [here][11].\n",
    "\n",
    "Note in this competition, a \"session\" actually means a unique \"user\". So our task is to predict what each of the `1,671,803` test \"users\" (i.e. \"sessions\") will do in the future. For each test \"user\" (i.e. \"session\") we must predict what they will `click`, `cart`, and `order` during the remainder of the week long test period.\n",
    "\n",
    "### Step 1 - Generate Candidates\n",
    "For each test user, we generate possible choices, i.e. candidates. In this notebook, we generate candidates from 5 sources:\n",
    "* User history of clicks, carts, orders\n",
    "* Most popular 20 clicks, carts, orders during test week\n",
    "* Co-visitation matrix of click/cart/order to cart/order with type weighting\n",
    "* Co-visitation matrix of cart/order to cart/order called buy2buy\n",
    "* Co-visitation matrix of click/cart/order to clicks with time weighting\n",
    "\n",
    "### Step 2 - ReRank and Choose 20\n",
    "Given the list of candidates, we must select 20 to be our predictions. In this notebook, we do this with a set of handcrafted rules. We can improve our predictions by training an XGBoost model to select for us. Our handcrafted rules give priority to:\n",
    "* Most recent previously visited items\n",
    "* Items previously visited multiple times\n",
    "* Items previously in cart or order\n",
    "* Co-visitation matrix of cart/order to cart/order\n",
    "* Current popular items\n",
    "\n",
    "![](https://raw.githubusercontent.com/cdeotte/Kaggle_Images/main/Nov-2022/c_r_model.png)\n",
    "  \n",
    "# Credits\n",
    "We thank many Kagglers who have shared ideas. We use co-visitation matrix idea from Vladimir [here][1]. We use groupby sort logic from Sinan in comment section [here][4]. We use duplicate prediction removal logic from Radek [here][5]. We use multiple visit logic from Pietro [here][2]. We use type weighting logic from Ingvaras [here][3]. We use leaky test data from my previous notebook [here][4]. And some ideas may have originated from Tawara [here][6] and KJ [here][7]. We use Colum2131's parquets [here][8]. Above image is from Ravi's discussion about candidate rerank models [here][9]\n",
    "\n",
    "[1]: https://www.kaggle.com/code/vslaykovsky/co-visitation-matrix\n",
    "[2]: https://www.kaggle.com/code/pietromaldini1/multiple-clicks-vs-latest-items\n",
    "[3]: https://www.kaggle.com/code/ingvarasgalinskas/item-type-vs-multiple-clicks-vs-latest-items\n",
    "[4]: https://www.kaggle.com/code/cdeotte/test-data-leak-lb-boost\n",
    "[5]: https://www.kaggle.com/code/radek1/co-visitation-matrix-simplified-imprvd-logic\n",
    "[6]: https://www.kaggle.com/code/ttahara/otto-mors-aid-frequency-baseline\n",
    "[7]: https://www.kaggle.com/code/whitelily/co-occurrence-baseline\n",
    "[8]: https://www.kaggle.com/datasets/columbia2131/otto-chunk-data-inparquet-format\n",
    "[9]: https://www.kaggle.com/competitions/otto-recommender-system/discussion/364721\n",
    "[10]: https://www.kaggle.com/cdeotte/compute-validation-score-cv-564\n",
    "[11]: https://www.kaggle.com/competitions/otto-recommender-system/discussion/364991"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "Below are notes about versions:\n",
    "* **Version 1 LB 0.573** Uses popular ideas from public notebooks and adds additional co-visitation matrices and additional logic. Has CV `0.563`. See validation notebook version 2 [here][1].\n",
    "* **Version 2 LB 573** Refactor logic for `suggest_buys(df)` to make it clear how new co-visitation matrices are reranking the candidates by adding to candidate weights. Also new logic boosts CV by `+0.0003`. Also LB is slightly better too. See validation notebook version 3 [here][1]\n",
    "* **Version 3** is the same as version 2 but 1.5x faster co-visitation matrix computation!\n",
    "* **Version 4 LB 575** Use top20 for clicks and top15 for carts and buys (instead of top40 and top40). This boosts CV `+0.0015` hooray! New CV is `0.5647`. See validation version 5 [here][1]\n",
    "* **Version 5** is the same as version 4 but 2x faster co-visitation matrix computation! (and 3x faster than version 1)\n",
    "* **Version 6** Stay tuned for more versions...\n",
    "\n",
    "[1]: https://www.kaggle.com/code/cdeotte/compute-validation-score-cv-564"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "VER = 5\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os, sys, pickle, glob, gc\n",
    "from collections import Counter\n",
    "import itertools\n",
    "# import cudf, \n",
    "# print('We will use RAPIDS version',cudf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:27:19.588942Z",
     "iopub.status.busy": "2022-12-28T20:27:19.588565Z",
     "iopub.status.idle": "2022-12-28T20:27:19.593779Z",
     "shell.execute_reply": "2022-12-28T20:27:19.592559Z",
     "shell.execute_reply.started": "2022-12-28T20:27:19.588911Z"
    }
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "debug_train_file_num = 40\n",
    "debug_test_session_num = 100\n",
    "type_labels = {'clicks':0, 'carts':1, 'orders':2}\n",
    "DISK_PIECES = 4\n",
    "model_dir = '../model_training/candiate_v1/'\n",
    "\n",
    "rec_num = 40\n",
    "\n",
    "# data_dir = '../data/parquet/val/test.parquet'\n",
    "# submission_file = '../data/val_candidates.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_dir = '../data/parquet/test/*'\n",
    "submission_file = '../data/test_candidates.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00373,
     "end_time": "2022-11-10T16:03:20.9748",
     "exception": false,
     "start_time": "2022-11-10T16:03:20.97107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 1 - Candidate Generation with RAPIDS\n",
    "For candidate generation, we build three co-visitation matrices. One computes the popularity of cart/order given a user's previous click/cart/order. We apply type weighting to this matrix. One computes the popularity of cart/order given a user's previous cart/order. We call this \"buy2buy\" matrix. One computes the popularity of clicks given a user previously click/cart/order.  We apply time weighting to this matrix. We will use RAPIDS cuDF GPU to compute these matrices quickly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:21:11.595154Z",
     "iopub.status.busy": "2022-12-28T20:21:11.594581Z",
     "iopub.status.idle": "2022-12-28T20:21:11.601494Z",
     "shell.execute_reply": "2022-12-28T20:21:11.600519Z",
     "shell.execute_reply.started": "2022-12-28T20:21:11.595111Z"
    },
    "papermill": {
     "duration": 3.036143,
     "end_time": "2022-11-10T16:03:24.014816",
     "exception": false,
     "start_time": "2022-11-10T16:03:20.978673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00424,
     "end_time": "2022-11-10T16:03:24.023816",
     "exception": false,
     "start_time": "2022-11-10T16:03:24.019576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Compute Three Co-visitation Matrices with RAPIDS\n",
    "We will compute 3 co-visitation matrices using RAPIDS cuDF on GPU. This is 30x faster than using Pandas CPU like other public notebooks! For maximum speed, set the variable `DISK_PIECES` to the smallest number possible based on the GPU you are using without incurring memory errors. If you run this code offline with 32GB GPU ram, then you can use `DISK_PIECES = 1` and compute each co-visitation matrix in almost 1 minute! Kaggle's GPU only has 16GB ram, so we use `DISK_PIECES = 4` and it takes an amazing 3 minutes each! Below are some of the tricks to speed up computation\n",
    "* Use RAPIDS cuDF GPU instead of Pandas CPU\n",
    "* Read disk once and save in CPU RAM for later GPU multiple use\n",
    "* Process largest amount of data possible on GPU at one time\n",
    "* Merge data in two stages. Multiple small to single medium. Multiple medium to single large.\n",
    "* Write result as parquet instead of dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:21:12.035626Z",
     "iopub.status.busy": "2022-12-28T20:21:12.035282Z",
     "iopub.status.idle": "2022-12-28T20:21:12.046095Z",
     "shell.execute_reply": "2022-12-28T20:21:12.045131Z",
     "shell.execute_reply.started": "2022-12-28T20:21:12.035598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice([1, 3], 2, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-12-28T20:21:12.284619Z",
     "iopub.status.busy": "2022-12-28T20:21:12.284291Z",
     "iopub.status.idle": "2022-12-28T20:21:12.311012Z",
     "shell.execute_reply": "2022-12-28T20:21:12.310018Z",
     "shell.execute_reply.started": "2022-12-28T20:21:12.284590Z"
    },
    "papermill": {
     "duration": 0.063943,
     "end_time": "2022-11-10T16:03:24.091816",
     "exception": false,
     "start_time": "2022-11-10T16:03:24.027873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 556 µs, sys: 172 µs, total: 728 µs\n",
      "Wall time: 640 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CACHE FUNCTIONS\n",
    "def read_file(f):\n",
    "    return cudf.DataFrame( data_cache[f] )\n",
    "def read_file_to_cache(f):\n",
    "    df = pd.read_parquet(f)\n",
    "    df.ts = (df.ts/1000).astype('int32')\n",
    "    df['type'] = df['type'].map(type_labels).astype('int8')\n",
    "    return df\n",
    "\n",
    "# CACHE THE DATA ON CPU BEFORE PROCESSING ON GPU\n",
    "data_cache = {}\n",
    "files = glob.glob('../input/otto-chunk-data-inparquet-format/*_parquet/*')\n",
    "\n",
    "if DEBUG:\n",
    "    files = np.random.choice(files, debug_train_file_num, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:21:12.524301Z",
     "iopub.status.busy": "2022-12-28T20:21:12.523624Z",
     "iopub.status.idle": "2022-12-28T20:21:12.532048Z",
     "shell.execute_reply": "2022-12-28T20:21:12.530977Z",
     "shell.execute_reply.started": "2022-12-28T20:21:12.524264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:21:12.803112Z",
     "iopub.status.busy": "2022-12-28T20:21:12.800837Z",
     "iopub.status.idle": "2022-12-28T20:21:12.808258Z",
     "shell.execute_reply": "2022-12-28T20:21:12.807196Z",
     "shell.execute_reply.started": "2022-12-28T20:21:12.803063Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Number of files: {len(files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:21:13.087048Z",
     "iopub.status.busy": "2022-12-28T20:21:13.086139Z",
     "iopub.status.idle": "2022-12-28T20:21:28.093073Z",
     "shell.execute_reply": "2022-12-28T20:21:28.092001Z",
     "shell.execute_reply.started": "2022-12-28T20:21:13.086998Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for f in files: data_cache[f] = read_file_to_cache(f)\n",
    "\n",
    "# CHUNK PARAMETERS\n",
    "READ_CT = 5\n",
    "CHUNK = int( np.ceil( len(files)/6 ))\n",
    "print(f'We will process {len(files)} files, in groups of {READ_CT} and chunks of {CHUNK}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.004089,
     "end_time": "2022-11-10T16:03:24.100502",
     "exception": false,
     "start_time": "2022-11-10T16:03:24.096413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1) \"Carts Orders\" Co-visitation Matrix - Type Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:21:28.097231Z",
     "iopub.status.busy": "2022-12-28T20:21:28.096891Z",
     "iopub.status.idle": "2022-12-28T20:21:28.102083Z",
     "shell.execute_reply": "2022-12-28T20:21:28.100846Z",
     "shell.execute_reply.started": "2022-12-28T20:21:28.097203Z"
    }
   },
   "outputs": [],
   "source": [
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:21:28.104460Z",
     "iopub.status.busy": "2022-12-28T20:21:28.103828Z",
     "iopub.status.idle": "2022-12-28T20:22:24.535322Z",
     "shell.execute_reply": "2022-12-28T20:22:24.534185Z",
     "shell.execute_reply.started": "2022-12-28T20:21:28.104425Z"
    },
    "papermill": {
     "duration": 566.561189,
     "end_time": "2022-11-10T16:12:50.666123",
     "exception": false,
     "start_time": "2022-11-10T16:03:24.104934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "type_weight = {0:1, 1:6, 2:3}\n",
    "\n",
    "# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n",
    "SIZE = 1.86e6/DISK_PIECES\n",
    "\n",
    "# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "for PART in range(DISK_PIECES):\n",
    "    print()\n",
    "    print('### DISK PART',PART+1)\n",
    "    \n",
    "    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n",
    "    # => OUTER CHUNKS\n",
    "    for j in range(6):\n",
    "        a = j*CHUNK\n",
    "        b = min( (j+1)*CHUNK, len(files) )\n",
    "        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n",
    "        \n",
    "        # => INNER CHUNKS\n",
    "        for k in range(a,b,READ_CT):\n",
    "            # READ FILE\n",
    "            df = [read_file(files[k])]\n",
    "            for i in range(1,READ_CT): \n",
    "                if k+i<b: df.append( read_file(files[k+i]) )\n",
    "            df = cudf.concat(df,ignore_index=True,axis=0)\n",
    "            df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "            # USE TAIL OF SESSION\n",
    "            df = df.reset_index(drop=True)\n",
    "            df['n'] = df.groupby('session').cumcount()\n",
    "            df = df.loc[df.n<30].drop('n',axis=1)\n",
    "            # CREATE PAIRS\n",
    "            df = df.merge(df,on='session')\n",
    "            df = df.loc[ ((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n",
    "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
    "            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n",
    "            # ASSIGN WEIGHTS\n",
    "            df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "            df['wgt'] = df.type_y.map(type_weight)\n",
    "            df = df[['aid_x','aid_y','wgt']]\n",
    "            df.wgt = df.wgt.astype('float32')\n",
    "            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "            # COMBINE INNER CHUNKS\n",
    "            print(f\"####### k:a==== {k}:{a}\")\n",
    "            if k==a: \n",
    "                tmp2 = df\n",
    "            else: \n",
    "                tmp2 = tmp2.add(df, fill_value=0)\n",
    "            print(k,', ',end='')\n",
    "        print()\n",
    "        # COMBINE OUTER CHUNKS\n",
    "        if a==0: tmp = tmp2\n",
    "        else: tmp = tmp.add(tmp2, fill_value=0)\n",
    "        del tmp2, df\n",
    "        gc.collect()\n",
    "    # CONVERT MATRIX TO DICTIONARY\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "    # SAVE TOP 40\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "    tmp = tmp.loc[tmp.n<15].drop('n',axis=1)\n",
    "    # SAVE PART TO DISK (convert to pandas first uses less memory)\n",
    "    tmp.to_pandas().to_parquet(f'top_15_carts_orders_v{VER}_{PART}.pqt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03219,
     "end_time": "2022-11-10T16:12:50.730634",
     "exception": false,
     "start_time": "2022-11-10T16:12:50.698444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2) \"Buy2Buy\" Co-visitation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-12-28T20:22:24.538461Z",
     "iopub.status.busy": "2022-12-28T20:22:24.537820Z",
     "iopub.status.idle": "2022-12-28T20:22:34.843983Z",
     "shell.execute_reply": "2022-12-28T20:22:34.842867Z",
     "shell.execute_reply.started": "2022-12-28T20:22:24.538420Z"
    },
    "papermill": {
     "duration": 113.735315,
     "end_time": "2022-11-10T16:14:44.498182",
     "exception": false,
     "start_time": "2022-11-10T16:12:50.762867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n",
    "DISK_PIECES = 1\n",
    "SIZE = 1.86e6/DISK_PIECES\n",
    "\n",
    "# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "for PART in range(DISK_PIECES):\n",
    "    print()\n",
    "    print('### DISK PART',PART+1)\n",
    "    \n",
    "    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n",
    "    # => OUTER CHUNKS\n",
    "    for j in range(6):\n",
    "        a = j*CHUNK\n",
    "        b = min( (j+1)*CHUNK, len(files) )\n",
    "        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n",
    "        \n",
    "        # => INNER CHUNKS\n",
    "        for k in range(a,b,READ_CT):\n",
    "            # READ FILE\n",
    "            df = [read_file(files[k])]\n",
    "            for i in range(1,READ_CT): \n",
    "                if k+i<b: df.append( read_file(files[k+i]) )\n",
    "            df = cudf.concat(df,ignore_index=True,axis=0)\n",
    "            df = df.loc[df['type'].isin([1,2])] # ONLY WANT CARTS AND ORDERS\n",
    "            df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "            # USE TAIL OF SESSION\n",
    "            df = df.reset_index(drop=True)\n",
    "            df['n'] = df.groupby('session').cumcount()\n",
    "            df = df.loc[df.n<30].drop('n',axis=1)\n",
    "            # CREATE PAIRS\n",
    "            df = df.merge(df,on='session')\n",
    "            df = df.loc[ ((df.ts_x - df.ts_y).abs()< 14 * 24 * 60 * 60) & (df.aid_x != df.aid_y) ] # 14 DAYS\n",
    "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
    "            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n",
    "            # ASSIGN WEIGHTS\n",
    "            df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "            df['wgt'] = 1\n",
    "            df = df[['aid_x','aid_y','wgt']]\n",
    "            df.wgt = df.wgt.astype('float32')\n",
    "            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "            # COMBINE INNER CHUNKS\n",
    "            if k==a: tmp2 = df\n",
    "            else: tmp2 = tmp2.add(df, fill_value=0)\n",
    "            print(k,', ',end='')\n",
    "        print()\n",
    "        # COMBINE OUTER CHUNKS\n",
    "        if a==0: tmp = tmp2\n",
    "        else: tmp = tmp.add(tmp2, fill_value=0)\n",
    "        del tmp2, df\n",
    "        gc.collect()\n",
    "    # CONVERT MATRIX TO DICTIONARY\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "    # SAVE TOP 40\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "    tmp = tmp.loc[tmp.n<15].drop('n',axis=1)\n",
    "    # SAVE PART TO DISK (convert to pandas first uses less memory)\n",
    "    tmp.to_pandas().to_parquet(f'top_15_buy2buy_v{VER}_{PART}.pqt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04526,
     "end_time": "2022-11-10T16:14:44.58589",
     "exception": false,
     "start_time": "2022-11-10T16:14:44.54063",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3) \"Clicks\" Co-visitation Matrix - Time Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-12-28T20:22:40.425302Z",
     "iopub.status.busy": "2022-12-28T20:22:40.424951Z",
     "iopub.status.idle": "2022-12-28T20:23:37.056087Z",
     "shell.execute_reply": "2022-12-28T20:23:37.055038Z",
     "shell.execute_reply.started": "2022-12-28T20:22:40.425273Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2022-11-10T16:14:44.629032",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n",
    "DISK_PIECES = 4\n",
    "SIZE = 1.86e6/DISK_PIECES\n",
    "\n",
    "# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "for PART in range(DISK_PIECES):\n",
    "    print()\n",
    "    print('### DISK PART',PART+1)\n",
    "    \n",
    "    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n",
    "    # => OUTER CHUNKS\n",
    "    for j in range(6):\n",
    "        a = j*CHUNK\n",
    "        b = min( (j+1)*CHUNK, len(files) )\n",
    "        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n",
    "        \n",
    "        # => INNER CHUNKS\n",
    "        for k in range(a,b,READ_CT):\n",
    "            # READ FILE\n",
    "            df = [read_file(files[k])]\n",
    "            for i in range(1,READ_CT): \n",
    "                if k+i<b: df.append( read_file(files[k+i]) )\n",
    "            df = cudf.concat(df,ignore_index=True,axis=0)\n",
    "            df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "            # USE TAIL OF SESSION\n",
    "            df = df.reset_index(drop=True)\n",
    "            df['n'] = df.groupby('session').cumcount()\n",
    "            df = df.loc[df.n<30].drop('n',axis=1)\n",
    "            # CREATE PAIRS\n",
    "            df = df.merge(df,on='session')\n",
    "            df = df.loc[ ((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n",
    "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
    "            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n",
    "            # ASSIGN WEIGHTS\n",
    "            df = df[['session', 'aid_x', 'aid_y','ts_x']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "            df['wgt'] = 1 + 3*(df.ts_x - 1659304800)/(1662328791-1659304800)\n",
    "            df = df[['aid_x','aid_y','wgt']]\n",
    "            df.wgt = df.wgt.astype('float32')\n",
    "            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "            # COMBINE INNER CHUNKS\n",
    "            if k==a: tmp2 = df\n",
    "            else: tmp2 = tmp2.add(df, fill_value=0)\n",
    "            print(k,', ',end='')\n",
    "        print()\n",
    "        # COMBINE OUTER CHUNKS\n",
    "        if a==0: tmp = tmp2\n",
    "        else: tmp = tmp.add(tmp2, fill_value=0)\n",
    "        del tmp2, df\n",
    "        gc.collect()\n",
    "    # CONVERT MATRIX TO DICTIONARY\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "    # SAVE TOP 40\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "    tmp = tmp.loc[tmp.n<20].drop('n',axis=1)\n",
    "    # SAVE PART TO DISK (convert to pandas first uses less memory)\n",
    "    tmp.to_pandas().to_parquet(f'top_20_clicks_v{VER}_{PART}.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:23:37.058721Z",
     "iopub.status.busy": "2022-12-28T20:23:37.058074Z",
     "iopub.status.idle": "2022-12-28T20:23:37.358232Z",
     "shell.execute_reply": "2022-12-28T20:23:37.357110Z",
     "shell.execute_reply.started": "2022-12-28T20:23:37.058681Z"
    }
   },
   "outputs": [],
   "source": [
    "# FREE MEMORY\n",
    "del data_cache, tmp\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Step 2 - ReRank (choose 20) using handcrafted rules\n",
    "For description of the handcrafted rules, read this notebook's intro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:23:37.374474Z",
     "iopub.status.busy": "2022-12-28T20:23:37.373645Z",
     "iopub.status.idle": "2022-12-28T20:23:39.204345Z",
     "shell.execute_reply": "2022-12-28T20:23:39.203347Z",
     "shell.execute_reply.started": "2022-12-28T20:23:37.374436Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data has shape (6928123, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14399779</td>\n",
       "      <td>1149006</td>\n",
       "      <td>1662286377</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14399779</td>\n",
       "      <td>874377</td>\n",
       "      <td>1662286399</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14399779</td>\n",
       "      <td>1128815</td>\n",
       "      <td>1662286447</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14399779</td>\n",
       "      <td>1128815</td>\n",
       "      <td>1662286508</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14399779</td>\n",
       "      <td>1712154</td>\n",
       "      <td>1662286533</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session      aid          ts    type\n",
       "0  14399779  1149006  1662286377  clicks\n",
       "1  14399779   874377  1662286399  clicks\n",
       "2  14399779  1128815  1662286447  clicks\n",
       "3  14399779  1128815  1662286508  clicks\n",
       "4  14399779  1712154  1662286533  clicks"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_test(data_dir, debug=DEBUG):    \n",
    "    dfs = []\n",
    "    files = glob.glob(data_dir)\n",
    "    if debug:\n",
    "        files = files[:2]\n",
    "    for e, chunk_file in enumerate(files):\n",
    "        chunk = pd.read_parquet(chunk_file)\n",
    "        chunk.ts = (chunk.ts/1000).astype('int32')\n",
    "        if chunk['type'].dtype == str:\n",
    "            chunk['type'] = chunk['type'].map(type_labels).astype('int8')\n",
    "        dfs.append(chunk)\n",
    "    return pd.concat(dfs).reset_index(drop=True) #.astype({\"ts\": \"datetime64[ms]\"})\n",
    "\n",
    "test_df = load_test(data_dir=data_dir)\n",
    "print('Test data has shape',test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14399779</td>\n",
       "      <td>1149006</td>\n",
       "      <td>1662286377</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14399779</td>\n",
       "      <td>874377</td>\n",
       "      <td>1662286399</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14399779</td>\n",
       "      <td>1128815</td>\n",
       "      <td>1662286447</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14399779</td>\n",
       "      <td>1128815</td>\n",
       "      <td>1662286508</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14399779</td>\n",
       "      <td>1712154</td>\n",
       "      <td>1662286533</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session      aid          ts    type\n",
       "0  14399779  1149006  1662286377  clicks\n",
       "1  14399779   874377  1662286399  clicks\n",
       "2  14399779  1128815  1662286447  clicks\n",
       "3  14399779  1128815  1662286508  clicks\n",
       "4  14399779  1712154  1662286533  clicks"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5015409"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df['session'].unique())*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_test = pl.read_csv(submission_file)\n",
    "# def get_session(row):\n",
    "#     session = row\n",
    "# #     print(session)\n",
    "#     return session.split('_')[0]\n",
    "# def get_type(row):\n",
    "#     session = row\n",
    "# #     print(session)\n",
    "#     return session.split('_')[1]\n",
    "# def data_preprocess(train):\n",
    "#     return train.with_columns(\n",
    "#                 [\n",
    "#                     pl.col('labels').str.split(' '),\n",
    "#         #             pl.col('session_type').str.split('_').map(lambda s: s[0]),\n",
    "#                     pl.col('session_type').apply(lambda s: get_session(s)).alias('session'),\n",
    "#                     pl.col('session_type').apply(lambda s: get_type(s)).alias('type')\n",
    "#                 ]\n",
    "#             ).explode('labels').with_columns(\n",
    "#                 [\n",
    "#                     pl.col('labels').cast(pl.datatypes.Int32).alias('aid'),\n",
    "#                      pl.col('session').cast(pl.datatypes.Int32),\n",
    "#                     pl.col('type').apply(lambda x: type2id[x])\n",
    "#                 ]\n",
    "#             ).drop(['session_type', 'labels']).with_columns(\n",
    "#                 [\n",
    "#                     pl.col('session').cast(pl.datatypes.Int32),\n",
    "#                     pl.col('type').cast(pl.datatypes.UInt8),\n",
    "#                     pl.col('aid').cast(pl.datatypes.Int32)\n",
    "#                 ]\n",
    "#             )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session_df = new_test.with_columns(\n",
    "#     [\n",
    "#         pl.col('session_type').apply(lambda s: get_session(s)).alias('session')\n",
    "#     ]\n",
    "# ).drop(['session_type', 'labels']).unique().to_pandas()\n",
    "\n",
    "# len(set(session_df['session']) - set(test_df['session'].unique()))\n",
    "# len(set(test_df['session'].unique()) - set(session_df['session']))\n",
    "# len(set(test_df['session'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:23:39.256051Z",
     "iopub.status.busy": "2022-12-28T20:23:39.255368Z",
     "iopub.status.idle": "2022-12-28T20:24:56.610639Z",
     "shell.execute_reply": "2022-12-28T20:24:56.608078Z",
     "shell.execute_reply.started": "2022-12-28T20:23:39.256014Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are size of our 3 co-visitation matrices:\n",
      "1533542 684353 1533542\n",
      "CPU times: user 38 s, sys: 2.76 s, total: 40.8 s\n",
      "Wall time: 42.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def pqt_to_dict(df):\n",
    "    return df.groupby('aid_x').aid_y.apply(list).to_dict()\n",
    "# LOAD THREE CO-VISITATION MATRICES\n",
    "top_20_clicks = pqt_to_dict( pd.read_parquet(os.path.join(model_dir, f'top_20_clicks_v{VER}_0.pqt')) )\n",
    "for k in range(1,DISK_PIECES): \n",
    "    top_20_clicks.update( pqt_to_dict( pd.read_parquet(os.path.join(model_dir, f'top_20_clicks_v{VER}_{k}.pqt')) ) )\n",
    "top_20_buys = pqt_to_dict( pd.read_parquet(os.path.join(model_dir, f'top_15_carts_orders_v{VER}_0.pqt')) )\n",
    "for k in range(1,DISK_PIECES): \n",
    "    top_20_buys.update( pqt_to_dict( pd.read_parquet(os.path.join(model_dir, f'top_15_carts_orders_v{VER}_{k}.pqt') )) )\n",
    "top_20_buy2buy = pqt_to_dict( pd.read_parquet(os.path.join(model_dir, f'top_15_buy2buy_v{VER}_0.pqt')) )\n",
    "\n",
    "# TOP CLICKS AND ORDERS IN TEST\n",
    "top_clicks = test_df.loc[test_df['type']=='clicks','aid'].value_counts().index.values[:rec_num]\n",
    "top_orders = test_df.loc[test_df['type']=='orders','aid'].value_counts().index.values[:rec_num]\n",
    "\n",
    "print('Here are size of our 3 co-visitation matrices:')\n",
    "print( len( top_20_clicks ), len( top_20_buy2buy ), len( top_20_buys ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:25:48.811968Z",
     "iopub.status.busy": "2022-12-28T20:25:48.811590Z",
     "iopub.status.idle": "2022-12-28T20:25:48.868563Z",
     "shell.execute_reply": "2022-12-28T20:25:48.867131Z",
     "shell.execute_reply.started": "2022-12-28T20:25:48.811935Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "type_weight_multipliers = {'clicks': 1, 'carts': 6, 'orders': 3}\n",
    "# type_weight_multipliers = {0: 1, 1: 6, 2: 3}\n",
    "\n",
    "def suggest_clicks(df):\n",
    "    # USER HISTORY AIDS AND TYPES\n",
    "    aids=df.aid.tolist()\n",
    "    types = df.type.tolist()\n",
    "    unique_aids = list(dict.fromkeys(aids[::-1] ))\n",
    "    # RERANK CANDIDATES USING WEIGHTS\n",
    "    if len(unique_aids)>=rec_num:\n",
    "        weights=np.logspace(0.1,1,len(aids),base=2, endpoint=True)-1\n",
    "        aids_temp = Counter() \n",
    "        # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n",
    "        for aid,w,t in zip(aids,weights,types): \n",
    "            aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "        sorted_aids = [k for k,v in aids_temp.most_common(rec_num)]\n",
    "        return sorted_aids\n",
    "    # USE \"CLICKS\" CO-VISITATION MATRIX\n",
    "    aids2 = list(itertools.chain(*[top_20_clicks[aid] for aid in unique_aids if aid in top_20_clicks]))\n",
    "    # RERANK CANDIDATES\n",
    "    top_aids2 = [aid2 for aid2, cnt in Counter(aids2).most_common(rec_num) if aid2 not in unique_aids]    \n",
    "    result = unique_aids + top_aids2[:rec_num - len(unique_aids)]\n",
    "    # USE TOP20 TEST CLICKS\n",
    "    return result + list(top_clicks)[:rec_num-len(result)]\n",
    "\n",
    "def suggest_buys(df):\n",
    "    # USER HISTORY AIDS AND TYPES\n",
    "    aids=df.aid.tolist()\n",
    "    types = df.type.tolist()\n",
    "    # UNIQUE AIDS AND UNIQUE BUYS\n",
    "    unique_aids = list(dict.fromkeys(aids[::-1] ))\n",
    "    df = df.loc[(df['type']==1)|(df['type']==2)]\n",
    "    unique_buys = list(dict.fromkeys( df.aid.tolist()[::-1] ))\n",
    "    # RERANK CANDIDATES USING WEIGHTS\n",
    "    if len(unique_aids)>=rec_num:\n",
    "        weights=np.logspace(0.5,1,len(aids),base=2, endpoint=True)-1\n",
    "        aids_temp = Counter() \n",
    "        # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n",
    "        for aid,w,t in zip(aids,weights,types): \n",
    "            aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "        # RERANK CANDIDATES USING \"BUY2BUY\" CO-VISITATION MATRIX\n",
    "        aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in unique_buys if aid in top_20_buy2buy]))\n",
    "        for aid in aids3: aids_temp[aid] += 0.1\n",
    "        sorted_aids = [k for k,v in aids_temp.most_common(rec_num)]\n",
    "        return sorted_aids\n",
    "    # USE \"CART ORDER\" CO-VISITATION MATRIX\n",
    "    aids2 = list(itertools.chain(*[top_20_buys[aid] for aid in unique_aids if aid in top_20_buys]))\n",
    "    # USE \"BUY2BUY\" CO-VISITATION MATRIX\n",
    "    aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in unique_buys if aid in top_20_buy2buy]))\n",
    "    # RERANK CANDIDATES\n",
    "    top_aids2 = [aid2 for aid2, cnt in Counter(aids2+aids3).most_common(rec_num) if aid2 not in unique_aids] \n",
    "    result = unique_aids + top_aids2[:rec_num - len(unique_aids)]\n",
    "    # USE TOP20 TEST ORDERS\n",
    "    return result + list(top_orders)[:rec_num -len(result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:26:04.027760Z",
     "iopub.status.busy": "2022-12-28T20:26:04.027277Z",
     "iopub.status.idle": "2022-12-28T20:26:04.035084Z",
     "shell.execute_reply": "2022-12-28T20:26:04.033846Z",
     "shell.execute_reply.started": "2022-12-28T20:26:04.027715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6928123, 4)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:26:08.347641Z",
     "iopub.status.busy": "2022-12-28T20:26:08.347283Z",
     "iopub.status.idle": "2022-12-28T20:26:08.357675Z",
     "shell.execute_reply": "2022-12-28T20:26:08.356718Z",
     "shell.execute_reply.started": "2022-12-28T20:26:08.347613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14399779</td>\n",
       "      <td>1149006</td>\n",
       "      <td>1662286377</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14399779</td>\n",
       "      <td>874377</td>\n",
       "      <td>1662286399</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14399779</td>\n",
       "      <td>1128815</td>\n",
       "      <td>1662286447</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14399779</td>\n",
       "      <td>1128815</td>\n",
       "      <td>1662286508</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14399779</td>\n",
       "      <td>1712154</td>\n",
       "      <td>1662286533</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session      aid          ts    type\n",
       "0  14399779  1149006  1662286377  clicks\n",
       "1  14399779   874377  1662286399  clicks\n",
       "2  14399779  1128815  1662286447  clicks\n",
       "3  14399779  1128815  1662286508  clicks\n",
       "4  14399779  1712154  1662286533  clicks"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:28:53.301637Z",
     "iopub.status.busy": "2022-12-28T20:28:53.301146Z",
     "iopub.status.idle": "2022-12-28T20:28:53.704651Z",
     "shell.execute_reply": "2022-12-28T20:28:53.703357Z",
     "shell.execute_reply.started": "2022-12-28T20:28:53.301593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6928123, 4)\n",
      "(6928123, 4)\n"
     ]
    }
   ],
   "source": [
    "print(test_df.shape)\n",
    "# if DEBUG:\n",
    "#     sample_session = np.random.choice(test_df['session'].unique(), debug_test_session_num, replace=False)\n",
    "#     test_df = test_df[test_df['session'].isin(sample_session)]\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_df['session'].unique())*3 == 5015409"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Save to parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-28T20:29:02.114283Z",
     "iopub.status.busy": "2022-12-28T20:29:02.113578Z",
     "iopub.status.idle": "2022-12-28T20:29:02.221883Z",
     "shell.execute_reply": "2022-12-28T20:29:02.220811Z",
     "shell.execute_reply.started": "2022-12-28T20:29:02.114246Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 3.66 s, total: 1min 15s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_df_clicks = test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).apply(\n",
    "    lambda x: suggest_clicks(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_buys = test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).apply(\n",
    "    lambda x: suggest_buys(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pred_df_clicks.index.unique())*3 == 5015409"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pred_df_buys.index.unique())*3 == 5015409"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:29:35.003623Z",
     "iopub.status.busy": "2022-12-28T20:29:35.002711Z",
     "iopub.status.idle": "2022-12-28T20:29:35.015901Z",
     "shell.execute_reply": "2022-12-28T20:29:35.015023Z",
     "shell.execute_reply.started": "2022-12-28T20:29:35.003577Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clicks_pred_df = pd.DataFrame(pred_df_clicks.add_suffix(\"_clicks\"), columns=[\"labels\"]).reset_index()\n",
    "orders_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_orders\"), columns=[\"labels\"]).reset_index()\n",
    "carts_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_carts\"), columns=[\"labels\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:29:49.788566Z",
     "iopub.status.busy": "2022-12-28T20:29:49.788197Z",
     "iopub.status.idle": "2022-12-28T20:29:49.795367Z",
     "shell.execute_reply": "2022-12-28T20:29:49.794260Z",
     "shell.execute_reply.started": "2022-12-28T20:29:49.788535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1671803, 2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clicks_pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:29:59.211813Z",
     "iopub.status.busy": "2022-12-28T20:29:59.211433Z",
     "iopub.status.idle": "2022-12-28T20:29:59.220420Z",
     "shell.execute_reply": "2022-12-28T20:29:59.219438Z",
     "shell.execute_reply.started": "2022-12-28T20:29:59.211765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1671803, 2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:30:07.341610Z",
     "iopub.status.busy": "2022-12-28T20:30:07.340868Z",
     "iopub.status.idle": "2022-12-28T20:30:07.348858Z",
     "shell.execute_reply": "2022-12-28T20:30:07.347773Z",
     "shell.execute_reply.started": "2022-12-28T20:30:07.341558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1671803, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carts_pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12899779_clicks</td>\n",
       "      <td>[59625, 94230, 1253524, 1660529, 3295, 45290, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12899780_clicks</td>\n",
       "      <td>[1142000, 736515, 973453, 582732, 1502122, 889...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12899781_clicks</td>\n",
       "      <td>[918667, 199008, 194067, 57315, 141736, 146057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12899782_clicks</td>\n",
       "      <td>[1007613, 595994, 1033148, 834354, 479970, 169...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899783_clicks</td>\n",
       "      <td>[1817895, 607638, 1754419, 1216820, 1729553, 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           session                                             labels\n",
       "0  12899779_clicks  [59625, 94230, 1253524, 1660529, 3295, 45290, ...\n",
       "1  12899780_clicks  [1142000, 736515, 973453, 582732, 1502122, 889...\n",
       "2  12899781_clicks  [918667, 199008, 194067, 57315, 141736, 146057...\n",
       "3  12899782_clicks  [1007613, 595994, 1033148, 834354, 479970, 169...\n",
       "4  12899783_clicks  [1817895, 607638, 1754419, 1216820, 1729553, 3..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clicks_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:30:12.617330Z",
     "iopub.status.busy": "2022-12-28T20:30:12.616967Z",
     "iopub.status.idle": "2022-12-28T20:30:12.640406Z",
     "shell.execute_reply": "2022-12-28T20:30:12.639504Z",
     "shell.execute_reply.started": "2022-12-28T20:30:12.617301Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_df = pd.concat([clicks_pred_df, orders_pred_df, carts_pred_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:30:21.410389Z",
     "iopub.status.busy": "2022-12-28T20:30:21.410023Z",
     "iopub.status.idle": "2022-12-28T20:30:21.416435Z",
     "shell.execute_reply": "2022-12-28T20:30:21.415397Z",
     "shell.execute_reply.started": "2022-12-28T20:30:21.410360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5015409, 2)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12899779_clicks</td>\n",
       "      <td>[59625, 94230, 1253524, 1660529, 3295, 45290, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12899780_clicks</td>\n",
       "      <td>[1142000, 736515, 973453, 582732, 1502122, 889...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12899781_clicks</td>\n",
       "      <td>[918667, 199008, 194067, 57315, 141736, 146057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12899782_clicks</td>\n",
       "      <td>[1007613, 595994, 1033148, 834354, 479970, 169...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899783_clicks</td>\n",
       "      <td>[1817895, 607638, 1754419, 1216820, 1729553, 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           session                                             labels\n",
       "0  12899779_clicks  [59625, 94230, 1253524, 1660529, 3295, 45290, ...\n",
       "1  12899780_clicks  [1142000, 736515, 973453, 582732, 1502122, 889...\n",
       "2  12899781_clicks  [918667, 199008, 194067, 57315, 141736, 146057...\n",
       "3  12899782_clicks  [1007613, 595994, 1033148, 834354, 479970, 169...\n",
       "4  12899783_clicks  [1817895, 607638, 1754419, 1216820, 1729553, 3..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lst = pred_df['labels'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(num_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5015409.0\n",
       "mean          40.0\n",
       "std            0.0\n",
       "min           40.0\n",
       "25%           40.0\n",
       "50%           40.0\n",
       "75%           40.0\n",
       "max           40.0\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_lst.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode_df = pred_df.explode('labels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_session_type(row):\n",
    "#     original_session = row['session']\n",
    "#     session, type_str = original_session.split('_')\n",
    "#     session = int(session)\n",
    "#     type_int = type_labels[type_str]\n",
    "#     return session, type_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df.to_parquet('../data/candidate_submission.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission CSV\n",
    "Inferring test data with Pandas groupby is slow. We need to accelerate the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.columns = [\"session_type\", \"labels\"]\n",
    "pred_df[\"labels\"] = pred_df.labels.apply(lambda x: \" \".join(map(str,x)))\n",
    "pred_df.to_csv(submission_file, index=False)\n",
    "# pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pred_df) == 5015409"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/test_candidates.csv'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
